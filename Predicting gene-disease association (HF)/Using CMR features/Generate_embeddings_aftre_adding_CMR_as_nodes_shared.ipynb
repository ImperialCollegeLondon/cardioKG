{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123a0511-f8ab-4859-92ca-58dd29d18ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import numpy as np\n",
    "from graphdatascience import GraphDataScience\n",
    "from py2neo import Graph\n",
    "from neo4j import GraphDatabase\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import neo4jupyter\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling, remove_self_loops, add_self_loops, to_dense_adj, dense_to_sparse\n",
    "from torch_geometric.nn import VGAE,GAE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "#neo4jupyter.init_notebook_mode()\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8119444b-ad8f-4992-a7e3-95c0b1f591ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password= \"*******\"\n",
    "\n",
    "gds = GraphDataScience(uri, auth=(user, password))\n",
    "\n",
    "graph = Graph(uri, auth=(user, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5548ba2-5d00-425d-871c-caa1df7a1303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1257bd65-7125-4896-9ce1-e2d3fd81469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import networkx as nx\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "# Define a function to convert Neo4j graph to NetworkX graph\n",
    "def neo4j_to_networkx(driver):\n",
    "    # Initialize NetworkX graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Query nodes and add them to NetworkX graph with all properties\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (n) RETURN n.id AS nodeid, n.name AS name, properties(n) AS properties\")\n",
    "\n",
    "        for record in result:\n",
    "            node_id = record[\"nodeid\"]\n",
    "            properties = record[\"properties\"]\n",
    "            filtered_properties = {key: value for key, value in properties.items() if key not in ['name', 'id']}\n",
    "            # Directly use all properties without filtering\n",
    "            G.add_node(node_id, **filtered_properties)\n",
    "\n",
    "    # Query relationships and add them to NetworkX graph with properties\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (n)-[r]->(m) RETURN n.id AS nid, n.name AS source, m.id AS mid, m.name AS target, type(r) AS relation_type, properties(r) AS relation_properties\")\n",
    "\n",
    "        sn_id = []\n",
    "        tn_id = []\n",
    "        for record in result:\n",
    "            source = record[\"source\"]\n",
    "            sn_id.append(record[\"nid\"])\n",
    "            target = record[\"target\"]\n",
    "            tn_id.append(record[\"mid\"])\n",
    "            relation_type = record[\"relation_type\"]\n",
    "            relation_properties = record[\"relation_properties\"]\n",
    "            filtered_relation_properties={key: value for key, value in relation_properties.items() if key not in ['name', 'id']}\n",
    "\n",
    "            # Add the relationship with type and properties\n",
    "            G.add_edge(record[\"nid\"], record[\"mid\"], **filtered_relation_properties)\n",
    "\n",
    "    return G, sn_id, tn_id\n",
    "\n",
    "# Convert Neo4j graph to NetworkX graph\n",
    "G, sn_id, tn_id = neo4j_to_networkx(driver)\n",
    "\n",
    "# Close Neo4j driver\n",
    "driver.close()\n",
    "\n",
    "# Print summary of NetworkX graph\n",
    "#print(nx.info(G))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c6b464-2305-4a63-99c7-622402b2d2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18afa8d-59f9-48cf-8a46-25b16d00668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_n = sn_id\n",
    "dst_n = tn_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496313b-7d7c-4abf-915c-970c5bdd1abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf7bcbf-f48a-487b-88d7-9ca4ddd42601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import statistics\n",
    "\n",
    "relation_prop = []\n",
    "i=0\n",
    "for ed in G.edges(data=True):\n",
    "    \n",
    "    if len(ed[2]) > 0:\n",
    "        value = ed[2]['value']\n",
    "        # Check if the value is a string list or a single float\n",
    "        if isinstance(value, str) and value.startswith('[') and value.endswith(']'):\n",
    "            # Handle the case where value is a string representation of a list\n",
    "                value_list = ast.literal_eval(value)  # Convert string to list\n",
    "                float_values = [float(v) for v in value_list]  # Convert each element to float\n",
    "                relation_prop.append((ed[0],ed[1],[statistics.median(float_values)]))\n",
    "        else:\n",
    "            relation_prop.append((ed[0],ed[1],[float(value)]))\n",
    "\n",
    "    else:\n",
    "        relation_prop.append((ed[0], ed[1],[0.0]))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ab9c1-190a-426a-8f21-40f78baa91ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4fd8294-b27f-49b2-9fe7-4f1af9b3e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = relation_prop\n",
    "\n",
    "# Initialize the dictionary\n",
    "item_dict = {}\n",
    "item_ids_to_keep = [\n",
    "    30, 4492,6008,10094,10095,10584,10588,25874,30758,31957,32505,\n",
    "    32909,10585,10590,10586,10587,25871,25873,25872,25058,25059]\n",
    "\n",
    "# Iterate through items from 0 to 9 (assuming you want to test with 10 item IDs)\n",
    "for item_id in range(0, len(G)):\n",
    "    # Filter rows that match the current item_id\n",
    "    item_rows = [row for row in data if row[0] == item_id]\n",
    "    \n",
    "    if item_rows:  # If the item is exist in the list\n",
    "        filtered_rows = [(row[1], row[2][0]) for row in item_rows if row[1] in item_ids_to_keep]\n",
    "        \n",
    "        if ((len(filtered_rows)<21)|(not filtered_rows)):  # If no matching rows exist in item_ids_to_keep\n",
    "            item_dict[item_id] = [0.0] * 21\n",
    "        \n",
    "        else:\n",
    "            # Sort based on the second column (relationship id)\n",
    "            filtered_rows.sort(key=lambda x: x[0])\n",
    "            # Extract the values in sorted order\n",
    "            sorted_values = [value for _, value in filtered_rows]\n",
    "            item_dict[item_id] = sorted_values\n",
    "    else:\n",
    "        item_dict[item_id] = [0.0] * 21\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed4071-1ea7-4540-ab38-e05f9826873c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bb0b308-b6e8-4d5f-8d1d-3875a3741761",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_properties = {}\n",
    "for node, data in G.nodes(data=True):\n",
    "    node_properties[node] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e51a545-aa7d-4768-be20-475c32112135",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_node_properties = dict(sorted(node_properties.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d44ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18f8457-afef-4f5c-b797-89df30ea48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_of_arrays1 = []\n",
    "for inner_dict in sorted_node_properties.values():\n",
    "    inner_array = []\n",
    "    for value in inner_dict.values():\n",
    "        inner_array.append(float(value))\n",
    "    array_of_arrays1.append(inner_array)\n",
    "\n",
    "# Print the array of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6985c277-3dbf-4ed9-8d24-1a28d02c9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_of_arrays = [arr if arr else [-1] * 5 for arr in array_of_arrays1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb3485-d138-4f90-8b5f-ff6ac613181c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb6d00f3-6bbe-4165-8f62-154279cf2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example list of arrays with some empty arrays\n",
    "list_of_arrays = list(array_of_arrays)\n",
    "# Fill empty arrays with NaN\n",
    "filled_list_of_arrays = [arr if sum(arr) > 0 else np.full_like(list_of_arrays[0],-1) for arr in list_of_arrays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db26c456-758b-49e8-8197-d72b6c0a6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.vstack(filled_list_of_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6df6e9-c88a-4e11-ab15-d5847c75b56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea115cb6-4e88-4749-80f0-666a977c940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_relation_prop = np.array(list(item_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0874afe5-9c97-4985-8e38-b0d59ed0d675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33277, 21)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_relation_prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "448c8cb8-134f-4483-ba6d-c19038ab6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_row(row):\n",
    "    # Convert the row to a numpy array if it isn't already\n",
    "    \n",
    "    # Get the minimum and maximum values of the row\n",
    "    min_val = np.min(row)\n",
    "    max_val = np.max(row)\n",
    "    \n",
    "    # Normalize the row to the range [0, 1]\n",
    "    if max_val != min_val:\n",
    "        normalized_row = (row - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        # If all values in the row are the same, return an array of 0.5 (arbitrary choice)\n",
    "        normalized_row = np.full(row.shape, -1)\n",
    "    \n",
    "    return normalized_row\n",
    "\n",
    "def normalize_matrix(matrix):    \n",
    "    # Apply normalization to each row individually\n",
    "    normalized_matrix = np.array([normalize_row(row) for row in matrix])\n",
    "    \n",
    "    return normalized_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93bf6359-910e-417a-bd88-23a59eb12bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1=normalize_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae95d7d7-0542-45e4-a6a1-98e062fc9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_relation_prop1 = normalize_matrix(matrix_relation_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d47c4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_matrix = np.hstack((matrix1,matrix_relation_prop1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e39958d7-8c18-4d0e-b24e-a140b091eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "# Define a function to convert Neo4j graph to NetworkX graph\n",
    "def neo4j_to_networkx(driver):\n",
    "    # Initialize NetworkX graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Query nodes and add them to NetworkX graph with properties\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (n) RETURN n.id AS nodid, labels(n) AS lab, n.name AS name, properties(n) AS properties\")\n",
    "\n",
    "        node_type = []\n",
    "        node_idd = []\n",
    "        for record in result:\n",
    "            node_id = record[\"name\"]\n",
    "            properties = record[\"properties\"]\n",
    "            node_type=node_type+record[\"lab\"]\n",
    "            node_idd=node_idd+[record[\"nodid\"]]\n",
    "            filtered_properties = {key: value for key, value in properties.items() if key not in ['name', 'id']}\n",
    "            G.add_node(node_id, **filtered_properties)\n",
    "\n",
    "    # Query relationships and add them to NetworkX graph\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (n)-[r]->(m) RETURN n.id AS nid ,n.name AS source,m.id AS mid, m.name AS target, r.name AS relation_name\")\n",
    " \n",
    "        sn_id = []\n",
    "        tn_id = []\n",
    "        \n",
    "        for record in result:\n",
    "            source = record[\"source\"]\n",
    "            sn_id.append(record[\"nid\"])\n",
    "            target = record[\"target\"]\n",
    "            tn_id.append(record[\"mid\"])\n",
    "            relation_type = record[\"relation_name\"]\n",
    "\n",
    "            G.add_edge(record[\"source\"], record[\"target\"], relation_type=relation_type)\n",
    "            #G.add_edge(source,target, relation_type=relation_type)\n",
    "\n",
    "    return G,sn_id,tn_id,node_type,node_idd\n",
    "\n",
    "# Convert Neo4j graph to NetworkX graph\n",
    "G,sn_id,tn_id,node_type,node_idd= neo4j_to_networkx(driver)\n",
    "\n",
    "# Close Neo4j driver\n",
    "driver.close()\n",
    "\n",
    "# Print summary of NetworkX graph\n",
    "\n",
    "#print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26a5dfb0-38fe-4c9b-8a6e-4b9496569185",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_df = pd.DataFrame({'node_id':node_idd,'node_type':node_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b22bba8-ec09-4a68-969a-5708ec740bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_df_sorted = node_type_df.sort_values(by='node_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50a365-de41-44f0-92ab-acfe34af0bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a68f333-92b5-40d9-927a-99f010581b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_numbers(words):\n",
    "    # Create an empty dictionary to map words to unique numbers\n",
    "    word_to_id = {}\n",
    "    # Create an empty list to store the resulting numbers\n",
    "    numbers = []\n",
    "    \n",
    "    # Iterate over the list of words\n",
    "    for word in words:\n",
    "        # If the word is not already in the dictionary, add it with a new unique number\n",
    "        if word not in word_to_id:\n",
    "            word_to_id[word] = len(word_to_id) + 1\n",
    "        # Append the unique number to the result list\n",
    "        numbers.append(word_to_id[word])\n",
    "    \n",
    "    return np.array(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ab32322-22da-42ec-80fd-d526e132bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types = words_to_numbers(node_type_df_sorted.node_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874127a0-afdc-447b-9fc3-2974d496a907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3343f2a-867e-4576-98fd-a3223be864e6",
   "metadata": {},
   "source": [
    "### Tunning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fce88d6c-18fb-4e88-a9b4-cdfb4ef22c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torch_geometric.nn import GCNConv, dropout\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling, remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "from torch_geometric.nn import VGAE\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Encoder for the DVGAE\n",
    "class DVGAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_node_types):\n",
    "        super(DVGAEEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "        self.node_type_embedding = torch.nn.Embedding(num_node_types, out_channels)\n",
    "        self.linear_mu = torch.nn.Linear(out_channels * 2, out_channels)\n",
    "        self.linear_logstd = torch.nn.Linear(out_channels * 2, out_channels)\n",
    "        self.dropout = nn.Dropout(0.1)  # Dropout rate of 0.1\n",
    "\n",
    "    def forward(self, x, edge_index, node_type):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.1, training=self.training)  # Apply dropout\n",
    "        node_type_emb = self.node_type_embedding(node_type)\n",
    "        x_mu = self.conv_mu(x, edge_index)\n",
    "        x_logstd = self.conv_logstd(x, edge_index)\n",
    "        \n",
    "        # Concatenate GCN outputs with node type embeddings\n",
    "        x_mu = torch.cat([x_mu, node_type_emb], dim=-1)\n",
    "        x_logstd = torch.cat([x_logstd, node_type_emb], dim=-1)\n",
    "        \n",
    "        # Pass through linear layers to get the final mu and logstd\n",
    "        x_mu = self.linear_mu(x_mu)\n",
    "        x_logstd = self.linear_logstd(x_logstd)\n",
    "        \n",
    "        return x_mu, x_logstd\n",
    "\n",
    "# Decoder for the DVGAE\n",
    "class DVGAEDecoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DVGAEDecoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.3)  # Dropout rate of 0.3\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        # Reconstruct edges using the dot product of embeddings\n",
    "        edge_index = remove_self_loops(edge_index)[0]\n",
    "        edge_logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
    "        edge_logits = self.dropout(edge_logits)  # Apply dropout\n",
    "        return edge_logits\n",
    "\n",
    "        \n",
    "# The DVGAE model\n",
    "class DVGAE(VGAE):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(DVGAE, self).__init__(encoder, decoder)\n",
    "         \n",
    "    def recon_loss(self, z, pos_edge_index, neg_edge_index=None):\n",
    "        pos_loss = -torch.log(\n",
    "            torch.sigmoid((z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=1)) + 1e-15\n",
    "        ).mean()\n",
    "\n",
    "        if neg_edge_index is None:\n",
    "            neg_edge_index = negative_sampling(\n",
    "                edge_index=pos_edge_index, \n",
    "                num_nodes=z.size(0)\n",
    "            )\n",
    "\n",
    "        neg_loss = -torch.log(\n",
    "            1 - torch.sigmoid((z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=1)) + 1e-15\n",
    "        ).mean()\n",
    "\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "    def kl_loss(self, mu, logstd):\n",
    "        return -0.5 * torch.mean(torch.sum(1 + 2 * logstd - mu**2 - torch.exp(2 * logstd), dim=1))\n",
    "\n",
    "    def reconstruct_graph(self, z, threshold):\n",
    "        # Remove self-loops\n",
    "        edge_index = remove_self_loops(data.edge_index)[0]\n",
    "        \n",
    "        # Reconstruct edges using the decoder\n",
    "        edge_logits = self.decoder(z, edge_index)\n",
    "    \n",
    "        # Apply sigmoid to get probabilities\n",
    "        edge_probs = torch.sigmoid(edge_logits)\n",
    "        \n",
    "        # Reconstruct the graph based on a threshold\n",
    "        adj_matrix = to_dense_adj(edge_index, edge_attr=edge_probs)\n",
    "        reconstructed_adj = (adj_matrix > threshold).float()\n",
    "        \n",
    "        # Convert dense adjacency matrix back to sparse format\n",
    "        reconstructed_edge_index, _ = dense_to_sparse(reconstructed_adj)\n",
    "        return reconstructed_edge_index\n",
    "\n",
    "\n",
    "# Define a function for grid search with validation\n",
    "# Define a function for grid search with validation\n",
    "def grid_search_with_validation(learning_rates, epochs_list, latent_dims, train_data, val_data):\n",
    "    best_loss = float('inf')\n",
    "    best_lr = None\n",
    "    best_model = None\n",
    "    best_epoch = None\n",
    "    best_latent_dim = None  # To store the best latent dimension\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        for epoch in epochs_list:\n",
    "            for latent_dim in latent_dims:  # Iterate over latent dimensions\n",
    "                model, optimizer = initialize_model(lr, epoch, latent_dim, len(val_data.node_type))\n",
    "\n",
    "                for _ in range(epoch):\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    z = model.encode(train_data.x, train_data.edge_index, train_data.node_type)\n",
    "                    mu, logstd = model.encoder(train_data.x, train_data.edge_index, train_data.node_type)\n",
    "                    recon_loss = model.recon_loss(z, train_data.edge_index)\n",
    "                    kl_loss = model.kl_loss(mu, logstd)\n",
    "                    total_loss = recon_loss + (1 / train_data.num_nodes) * kl_loss\n",
    "                    total_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                val_loss = evaluate_model(model, val_data)\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_lr = lr\n",
    "                    best_model = model\n",
    "                    best_epoch = epoch\n",
    "                    best_latent_dim = latent_dim  # Store the best latent dimension\n",
    "\n",
    "    return best_lr, best_model, best_epoch, best_latent_dim  # Return the best latent dimension\n",
    "\n",
    "    \n",
    "# Function to initialize the model with given hyperparameters\n",
    "def initialize_model(lr, epoch, latent_dim, num_node_types):\n",
    "    encoder = DVGAEEncoder(in_channels, latent_dim, num_node_types)  # Use latent_dim here\n",
    "    decoder = DVGAEDecoder()\n",
    "    model = DVGAE(encoder, decoder)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, optimizer\n",
    "\n",
    "def evaluate_model(model, val_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(val_data.x, val_data.edge_index,val_data.node_type)\n",
    "        mu, logstd = model.encoder(val_data.x, val_data.edge_index,val_data.node_type)\n",
    "        recon_loss = model.recon_loss(z, val_data.edge_index)\n",
    "        kl_loss = model.kl_loss(mu, logstd)\n",
    "        total_loss = recon_loss + (1 / data.num_nodes) * kl_loss\n",
    "    return total_loss.item()\n",
    "\n",
    "\n",
    "# Assuming you have already defined your Data object\n",
    "\n",
    "\n",
    "\n",
    "# Sample data\n",
    "torch.manual_seed(123456)\n",
    "# Sample directed graph with node features and types\n",
    "num_nodes = result_matrix.shape[0]\n",
    "edge_index = torch.tensor([src_n, dst_n], dtype=torch.long)  # Directed edges\n",
    "x = torch.tensor(result_matrix, dtype=torch.float)  # Node features\n",
    "node_types = torch.tensor(node_types, dtype=torch.long)  # Node types\n",
    "\n",
    "# Ensure that node types are within the range of unique types\n",
    "num_node_types = node_types.max().item()+1\n",
    "data = Data(x=x, edge_index=edge_index, node_type=node_types)\n",
    "num_nodes = data.num_nodes\n",
    "num_edges = data.num_edges\n",
    "\n",
    "# Splitting the node indices\n",
    "train_ratio = 0.7  # 70% training, 30% validation\n",
    "num_train_nodes = int(train_ratio * num_nodes)\n",
    "train_node_indices = torch.arange(num_train_nodes)\n",
    "val_node_indices = torch.arange(num_train_nodes, num_nodes)\n",
    "\n",
    "# Filtering the edges based on the selected node indices\n",
    "train_edge_mask = (data.edge_index[0] < num_train_nodes) & (data.edge_index[1] < num_train_nodes)\n",
    "train_edge_index = data.edge_index[:, train_edge_mask]\n",
    "val_edge_mask = ~train_edge_mask\n",
    "val_edge_index = data.edge_index[:, val_edge_mask]\n",
    "\n",
    "# Filter node types\n",
    "train_node_type = data.node_type[train_node_indices]\n",
    "val_node_type = data.node_type[val_node_indices]\n",
    "\n",
    "# Creating Data objects for training and validation\n",
    "train_data = Data(x=x, edge_index=train_edge_index, node_type=node_types)\n",
    "val_data = Data(x=x, edge_index=val_edge_index, node_type=node_types)\n",
    "\n",
    "in_channels = data.num_node_features\n",
    "#out_channels = 50  # Dimension of the latent space\n",
    "\n",
    "\n",
    "# Perform grid search for learning rate, number of epochs, and latent space dimensions\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "epochs = [100, 200, 300]\n",
    "latent_dims = [50]  # Add your desired latent space dimensions\n",
    "\n",
    "best_lr, best_model, best_epoch, best_latent_dim = grid_search_with_validation(learning_rates, epochs, latent_dims, train_data, val_data)\n",
    "\n",
    "# Initialize the model with the best hyperparameters\n",
    "best_model, optimizer = initialize_model(best_lr, best_epoch, best_latent_dim, len(node_types))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a337da7e-375e-4f77-9004-5cf5cd1d3a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "279fa80d-df28-4935-b62c-5f9a3f25508e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f48d8568-41fb-4afa-bee0-b3a74bda99c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "556ba0ae-8940-4abf-99fa-4733eee578f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(best_epoch):\n",
    "    best_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = best_model.encode(data.x, data.edge_index,data.node_type)\n",
    "    mu, logstd = best_model.encoder(data.x, data.edge_index,data.node_type)\n",
    "    recon_loss = best_model.recon_loss(z, data.edge_index)\n",
    "    kl_loss = best_model.kl_loss(mu, logstd)\n",
    "    total_loss = recon_loss + (1 / data.num_nodes) * kl_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}/{best_epoch}, Loss: {total_loss.item()}\")\n",
    "\n",
    "# Obtain the embeddings\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    z = best_model.encode(data.x, data.edge_index,data.node_type)\n",
    "    print(\"Node Embeddings:\")\n",
    "    print(z)\n",
    "\n",
    "# Reconstruct the graph\n",
    "with torch.no_grad():\n",
    "    reconstructed_edge_index = best_model.reconstruct_graph(z, threshold=0.5)\n",
    "    print(\"Reconstructed Edge Index:\")\n",
    "    print(reconstructed_edge_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9fddc-4e83-42df-a60c-0d67ad96595c",
   "metadata": {},
   "source": [
    "### end of tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00e0da1f-a9fd-4fab-b581-98a606d77dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torch_geometric.nn import GCNConv, dropout\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling, remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "from torch_geometric.nn import VGAE\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Encoder for the DVGAE\n",
    "class DVGAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_node_types):\n",
    "        super(DVGAEEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "        self.node_type_embedding = torch.nn.Embedding(num_node_types, out_channels)\n",
    "        self.linear_mu = torch.nn.Linear(out_channels * 2, out_channels)\n",
    "        self.linear_logstd = torch.nn.Linear(out_channels * 2, out_channels)\n",
    "        self.dropout = nn.Dropout(0.1)  # Dropout rate of 0.1\n",
    "\n",
    "    def forward(self, x, edge_index, node_type):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.1, training=self.training)  # Apply dropout\n",
    "        node_type_emb = self.node_type_embedding(node_type)\n",
    "        x_mu = self.conv_mu(x, edge_index)\n",
    "        x_logstd = self.conv_logstd(x, edge_index)\n",
    "        \n",
    "        # Concatenate GCN outputs with node type embeddings\n",
    "        x_mu = torch.cat([x_mu, node_type_emb], dim=-1)\n",
    "        x_logstd = torch.cat([x_logstd, node_type_emb], dim=-1)\n",
    "        \n",
    "        # Pass through linear layers to get the final mu and logstd\n",
    "        x_mu = self.linear_mu(x_mu)\n",
    "        x_logstd = self.linear_logstd(x_logstd)\n",
    "        \n",
    "        return x_mu, x_logstd\n",
    "\n",
    "# Decoder for the DVGAE\n",
    "class DVGAEDecoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DVGAEDecoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.3)  # Dropout rate of 0.3\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        # Reconstruct edges using the dot product of embeddings\n",
    "        edge_index = remove_self_loops(edge_index)[0]\n",
    "        edge_logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
    "        edge_logits = self.dropout(edge_logits)  # Apply dropout\n",
    "        return edge_logits\n",
    "\n",
    "        \n",
    "# The DVGAE model\n",
    "class DVGAE(VGAE):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(DVGAE, self).__init__(encoder, decoder)\n",
    "         \n",
    "    def recon_loss(self, z, pos_edge_index, neg_edge_index=None):\n",
    "        pos_loss = -torch.log(\n",
    "            torch.sigmoid((z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=1)) + 1e-15\n",
    "        ).mean()\n",
    "\n",
    "        if neg_edge_index is None:\n",
    "            neg_edge_index = negative_sampling(\n",
    "                edge_index=pos_edge_index, \n",
    "                num_nodes=z.size(0)\n",
    "            )\n",
    "\n",
    "        neg_loss = -torch.log(\n",
    "            1 - torch.sigmoid((z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=1)) + 1e-15\n",
    "        ).mean()\n",
    "\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "    def kl_loss(self, mu, logstd):\n",
    "        return -0.5 * torch.mean(torch.sum(1 + 2 * logstd - mu**2 - torch.exp(2 * logstd), dim=1))\n",
    "\n",
    "    def reconstruct_graph(self, z, threshold):\n",
    "        # Remove self-loops\n",
    "        edge_index = remove_self_loops(data.edge_index)[0]\n",
    "        \n",
    "        # Reconstruct edges using the decoder\n",
    "        edge_logits = self.decoder(z, edge_index)\n",
    "    \n",
    "        # Apply sigmoid to get probabilities\n",
    "        edge_probs = torch.sigmoid(edge_logits)\n",
    "        \n",
    "        # Reconstruct the graph based on a threshold\n",
    "        adj_matrix = to_dense_adj(edge_index, edge_attr=edge_probs)\n",
    "        reconstructed_adj = (adj_matrix > threshold).float()\n",
    "        \n",
    "        # Convert dense adjacency matrix back to sparse format\n",
    "        reconstructed_edge_index, _ = dense_to_sparse(reconstructed_adj)\n",
    "        return reconstructed_edge_index\n",
    "\n",
    "\n",
    "# Define a function for grid search with validation\n",
    "# Define a function for grid search with validation\n",
    "def grid_search_with_validation(learning_rates, epochs_list, latent_dims, train_data, val_data):\n",
    "    best_loss = float('inf')\n",
    "    best_lr = None\n",
    "    best_model = None\n",
    "    best_epoch = None\n",
    "    best_latent_dim = None  # To store the best latent dimension\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        for epoch in epochs_list:\n",
    "            for latent_dim in latent_dims:  # Iterate over latent dimensions\n",
    "                model, optimizer = initialize_model(lr, epoch, latent_dim, len(val_data.node_type))\n",
    "\n",
    "                for _ in range(epoch):\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    z = model.encode(train_data.x, train_data.edge_index, train_data.node_type)\n",
    "                    mu, logstd = model.encoder(train_data.x, train_data.edge_index, train_data.node_type)\n",
    "                    recon_loss = model.recon_loss(z, train_data.edge_index)\n",
    "                    kl_loss = model.kl_loss(mu, logstd)\n",
    "                    total_loss = recon_loss + (1 / train_data.num_nodes) * kl_loss\n",
    "                    total_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                val_loss = evaluate_model(model, val_data)\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_lr = lr\n",
    "                    best_model = model\n",
    "                    best_epoch = epoch\n",
    "                    best_latent_dim = latent_dim  # Store the best latent dimension\n",
    "\n",
    "    return best_lr, best_model, best_epoch, best_latent_dim  # Return the best latent dimension\n",
    "\n",
    "    \n",
    "# Function to initialize the model with given hyperparameters\n",
    "def initialize_model(lr, epoch, latent_dim, num_node_types):\n",
    "    encoder = DVGAEEncoder(in_channels, latent_dim, num_node_types)  # Use latent_dim here\n",
    "    decoder = DVGAEDecoder()\n",
    "    model = DVGAE(encoder, decoder)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, optimizer\n",
    "\n",
    "def evaluate_model(model, val_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(val_data.x, val_data.edge_index,val_data.node_type)\n",
    "        mu, logstd = model.encoder(val_data.x, val_data.edge_index,val_data.node_type)\n",
    "        recon_loss = model.recon_loss(z, val_data.edge_index)\n",
    "        kl_loss = model.kl_loss(mu, logstd)\n",
    "        total_loss = recon_loss + (1 / data.num_nodes) * kl_loss\n",
    "    return total_loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80cc531e-f21f-4aa7-aa37-98ad8e43dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types = words_to_numbers(node_type_df_sorted.node_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c16c2be5-059d-4eae-96f0-3317fdc42eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "torch.manual_seed(123456)\n",
    "# Sample directed graph with node features and types\n",
    "num_nodes = result_matrix.shape[0]\n",
    "edge_index = torch.tensor([src_n, dst_n], dtype=torch.long)  # Directed edges\n",
    "x = torch.tensor(result_matrix, dtype=torch.float) # Node features\n",
    "node_types = torch.tensor(node_types, dtype=torch.long)  # Node types\n",
    "\n",
    "# Ensure that node types are within the range of unique types\n",
    "num_node_types = node_types.max().item()+1\n",
    "data = Data(x=x, edge_index=edge_index, node_type=node_types)\n",
    "\n",
    "# Define the model\n",
    "in_channels = data.num_node_features\n",
    "out_channels = 50  # Dimension of the latent space\n",
    "encoder = DVGAEEncoder(in_channels, out_channels, num_node_types)\n",
    "decoder = DVGAEDecoder()\n",
    "model = DVGAE(encoder, decoder)\n",
    "\n",
    "# Training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index, data.node_type)\n",
    "    mu, logstd = model.encoder(data.x, data.edge_index, data.node_type)\n",
    "    recon_loss = model.recon_loss(z, data.edge_index)\n",
    "    kl_loss = model.kl_loss(mu, logstd)\n",
    "    total_loss = recon_loss + (1 / data.num_nodes) * kl_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss.item()}\")\n",
    "\n",
    "# Obtain the embeddings\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(data.x, data.edge_index, data.node_type)\n",
    "    print(\"Node Embeddings:\")\n",
    "    print(z)\n",
    "\n",
    "# Reconstruct the graph\n",
    "with torch.no_grad():\n",
    "    reconstructed_edge_index = model.reconstruct_graph(z, threshold=0.5)\n",
    "    print(\"Reconstructed Edge Index:\")\n",
    "    print(reconstructed_edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f081a04-0001-405f-9848-fe651151adec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge-wise Accuracy: 0.9912135109314532\n",
      "Precision: 1.0\n",
      "Recall: 0.9912135109314532\n",
      "F1 Score: 0.9955873697017872\n"
     ]
    }
   ],
   "source": [
    "# Convert edge indices to sets for easy comparison\n",
    "original_edge_set = {(edge_index[0, i].item(), edge_index[1, i].item()) for i in range(edge_index.size(1))}\n",
    "reconstructed_edge_set = {(reconstructed_edge_index[0, i].item(), reconstructed_edge_index[1, i].item()) for i in range(reconstructed_edge_index.size(1))}\n",
    "\n",
    "# Compute the true positive, false positive, and false negative edges\n",
    "true_positives = original_edge_set.intersection(reconstructed_edge_set)\n",
    "false_positives = reconstructed_edge_set - original_edge_set\n",
    "false_negatives = original_edge_set - reconstructed_edge_set\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = len(true_positives) / len(original_edge_set)\n",
    "precision = len(true_positives) / (len(true_positives) + len(false_positives))\n",
    "recall = len(true_positives) / (len(true_positives) + len(false_negatives))\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Edge-wise Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fb94b2c-01ab-45d1-b474-8b4e218ae13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13443, 13443, 13963,  ..., 32336, 32336, 32336],\n",
       "        [28245, 12993, 12993,  ..., 31957, 32505, 32909]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0a99840-529e-40ef-b080-f274dc586d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1195437])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0db46bc1-236b-49e6-b168-534343511a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1=z.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db1a198-0f45-46c0-a8b8-01b60f693f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2f40ff4-ddce-40f6-aff3-22f8001711de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "# Define a function to convert Neo4j graph to NetworkX graph\n",
    "def neo4j_to_networkx(driver):\n",
    "    # Initialize NetworkX graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Query nodes and add them to NetworkX graph with properties\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (n) RETURN n.id AS nodid, labels(n) AS lab, n.name AS name, properties(n) AS properties\")\n",
    "\n",
    "        node_type = []\n",
    "        for record in result:\n",
    "            node_id = record[\"name\"]\n",
    "            properties = record[\"properties\"]\n",
    "            node_type=node_type+record[\"lab\"]\n",
    "            filtered_properties = {key: value for key, value in properties.items() if key not in ['name', 'id']}\n",
    "            G.add_node(node_id, **filtered_properties)\n",
    "\n",
    "    # Query relationships and add them to NetworkX graph\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (n)-[r]->(m) RETURN n.id AS nid ,n.name AS source,m.id AS mid, m.name AS target, r.name AS relation_name\")\n",
    " \n",
    "        sn_id = []\n",
    "        tn_id = []\n",
    "        source =[]\n",
    "        target = []\n",
    "        for record in result:\n",
    "            source.append(record[\"source\"])\n",
    "            sn_id.append(record[\"nid\"])\n",
    "            target.append(record[\"target\"])\n",
    "            tn_id.append(record[\"mid\"])\n",
    "            relation_type = record[\"relation_name\"]\n",
    "\n",
    "            G.add_edge(record[\"source\"], record[\"target\"], relation_type=relation_type)\n",
    "            #G.add_edge(source,target, relation_type=relation_type)\n",
    "\n",
    "    return G,sn_id,tn_id,source,target,node_type\n",
    "\n",
    "# Convert Neo4j graph to NetworkX graph\n",
    "G,sn_id,tn_id,source,target,node_type= neo4j_to_networkx(driver)\n",
    "\n",
    "# Close Neo4j driver\n",
    "driver.close()\n",
    "\n",
    "# Print summary of NetworkX graph\n",
    "\n",
    "#print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f808bd-b874-4210-a274-7ba440a304d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "046c65ad-ef2b-43f0-b33e-aacae097e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_info = pd.concat([pd.Series(sn_id),pd.Series(source)],axis=1)\n",
    "source_info1 = source_info.drop_duplicates()\n",
    "source_info1.columns = ['id','name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "29a86e24-5847-46f7-b78a-7f5e9556c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_info = pd.concat([pd.Series(tn_id),pd.Series(target)],axis=1)\n",
    "target_info1 = target_info.drop_duplicates()\n",
    "target_info1.columns = ['id','name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18e3662e-feba-4d9a-97c7-cd0a2fca87d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13443</td>\n",
       "      <td>P1055632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13963</td>\n",
       "      <td>P1303106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14137</td>\n",
       "      <td>P1391040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14341</td>\n",
       "      <td>P1491610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14561</td>\n",
       "      <td>P1593721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350180</th>\n",
       "      <td>8596</td>\n",
       "      <td>Hypnagogic hallucinations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350492</th>\n",
       "      <td>6017</td>\n",
       "      <td>Encephalocele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350699</th>\n",
       "      <td>6868</td>\n",
       "      <td>Febrile seizure (within the age range of 3 mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350762</th>\n",
       "      <td>28136</td>\n",
       "      <td>Scrotal pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350764</th>\n",
       "      <td>10721</td>\n",
       "      <td>Low-set ears</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               name\n",
       "0       13443                                           P1055632\n",
       "2       13963                                           P1303106\n",
       "3       14137                                           P1391040\n",
       "5       14341                                           P1491610\n",
       "6       14561                                           P1593721\n",
       "...       ...                                                ...\n",
       "350180   8596                          Hypnagogic hallucinations\n",
       "350492   6017                                      Encephalocele\n",
       "350699   6868  Febrile seizure (within the age range of 3 mon...\n",
       "350762  28136                                       Scrotal pain\n",
       "350764  10721                                       Low-set ears\n",
       "\n",
       "[33277 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_tg_info = pd.concat([source_info1,target_info1])\n",
    "sr_tg_info1 = sr_tg_info.drop_duplicates()\n",
    "sr_tg_info1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "638dcd71-4f80-469c-b794-fcfc75cc2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_tg_info_sorted = sr_tg_info1.sort_values(by='id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18c59b0f-8a09-48d7-9393-927639415f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings = {node: z1[i] for i, node in zip(sr_tg_info_sorted.id,sr_tg_info_sorted.name)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d9fc0-56f3-4768-83a3-4756bb5b517c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ff5d2317-27f5-43de-b69a-8f651c6c870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('node_embeddings_50d.pkl', 'wb') as pkl_file:\n",
    "    pickle.dump(node_embeddings, pkl_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
